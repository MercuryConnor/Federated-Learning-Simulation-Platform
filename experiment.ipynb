{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6993d24a",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c415f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project modules\n",
    "from config import ExperimentConfig\n",
    "from dataset import generate_synthetic_dataset, partition_data_for_clients, create_centralized_datasets, get_dataset_statistics\n",
    "from model import create_compiled_model, get_model_summary, count_model_parameters\n",
    "from centralized import CentralizedTrainer, run_centralized_experiment\n",
    "from visualization import plot_training_convergence, plot_final_comparison, plot_client_participation, create_performance_summary_table, generate_all_visualizations\n",
    "\n",
    "# Try importing federated module (may fail if TensorFlow Federated not available)\n",
    "TFF_AVAILABLE = False\n",
    "try:\n",
    "    from federated import FederatedTrainer, run_federated_experiment\n",
    "    TFF_AVAILABLE = True\n",
    "    print(\"✅ TensorFlow Federated available - Full functionality enabled\")\n",
    "except ImportError as e:\n",
    "    print(\"⚠️  TensorFlow Federated not available - Federated experiments will be skipped\")\n",
    "    print(f\"   Error: {e}\")\n",
    "    print(\"   Note: This is expected on Python 3.12. Use Python 3.9-3.11 for full functionality.\")\n",
    "\n",
    "print(\"\\n✅ All available modules loaded successfully\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display experiment configuration\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "config = ExperimentConfig.get_config_summary()\n",
    "for key, value in config.items():\n",
    "    print(f\"{key:.<30} {value}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727fb84",
   "metadata": {},
   "source": [
    "## 2. Dataset Generation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "ExperimentConfig.set_random_seeds()\n",
    "\n",
    "# Generate synthetic dataset\n",
    "print(\"Generating synthetic dataset...\")\n",
    "X, y = generate_synthetic_dataset()\n",
    "\n",
    "print(f\"\\nDataset Properties:\")\n",
    "print(f\"  - Total samples: {len(X)}\")\n",
    "print(f\"  - Feature dimension: {X.shape[1]}\")\n",
    "print(f\"  - Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"  - Class distribution: {np.bincount(y)}\")\n",
    "print(f\"  - Class balance: {np.bincount(y) / len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96207289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition data for federated clients\n",
    "print(\"Partitioning data for federated clients...\")\n",
    "client_datasets = partition_data_for_clients(X, y, ExperimentConfig.NUM_CLIENTS)\n",
    "\n",
    "# Analyze client data distribution\n",
    "stats = get_dataset_statistics(client_datasets)\n",
    "\n",
    "print(f\"\\nFederated Client Statistics:\")\n",
    "print(f\"  - Number of clients: {stats['num_clients']}\")\n",
    "print(f\"  - Total samples distributed: {stats['total_samples']}\")\n",
    "print(f\"  - Samples per client (min/max/mean): {min(stats['samples_per_client'])}/{max(stats['samples_per_client'])}/{np.mean(stats['samples_per_client']):.1f}\")\n",
    "\n",
    "print(f\"\\nClass Distribution per Client (non-IID):\")\n",
    "for i, dist in enumerate(stats['class_distribution_per_client'][:5]):  # Show first 5 clients\n",
    "    print(f\"  Client {i}: {dist}\")\n",
    "print(f\"  ... (showing first 5 of {stats['num_clients']} clients)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create centralized dataset splits\n",
    "print(\"Creating centralized train/validation/test splits...\")\n",
    "centralized_data = create_centralized_datasets(X, y)\n",
    "\n",
    "X_train, y_train = centralized_data['train']\n",
    "X_val, y_val = centralized_data['validation']\n",
    "X_test, y_test = centralized_data['test']\n",
    "\n",
    "print(f\"\\nCentralized Splits:\")\n",
    "print(f\"  - Training: {X_train.shape}\")\n",
    "print(f\"  - Validation: {X_val.shape}\")\n",
    "print(f\"  - Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff59243",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876001c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture\n",
    "print(\"Model Architecture:\")\n",
    "print(get_model_summary())\n",
    "\n",
    "# Count parameters\n",
    "params = count_model_parameters()\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"  - Total: {params['total']:,}\")\n",
    "print(f\"  - Trainable: {params['trainable']:,}\")\n",
    "print(f\"  - Non-trainable: {params['non_trainable']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e1038",
   "metadata": {},
   "source": [
    "## 4. Centralized Training Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d43f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run centralized training\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING CENTRALIZED TRAINING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Combine train and validation for full training\n",
    "X_full_train = np.vstack([X_train, X_val])\n",
    "y_full_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "# Create trainer\n",
    "centralized_trainer = CentralizedTrainer()\n",
    "\n",
    "# Train model\n",
    "centralized_history = centralized_trainer.train(\n",
    "    X_full_train, y_full_train,\n",
    "    epochs=ExperimentConfig.CENTRALIZED_EPOCHS,\n",
    "    batch_size=ExperimentConfig.BATCH_SIZE,\n",
    "    validation_split=ExperimentConfig.VALIDATION_SPLIT,\n",
    "    verbose=0  # Suppress epoch-by-epoch output\n",
    ")\n",
    "\n",
    "print(\"\\nCentralized training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate centralized model on test set\n",
    "centralized_test_metrics = centralized_trainer.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nCentralized Model - Test Set Results:\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in centralized_test_metrics.items():\n",
    "    print(f\"{metric:.<35} {value:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save centralized results\n",
    "centralized_results_path = centralized_trainer.save_results(centralized_test_metrics)\n",
    "centralized_model_path = centralized_trainer.save_model()\n",
    "\n",
    "print(f\"\\nCentralized results saved to: {centralized_results_path}\")\n",
    "print(f\"Centralized model saved to: {centralized_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f36b8",
   "metadata": {},
   "source": [
    "## 5. Federated Learning Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run federated training (skip if TFF not available)\n",
    "if not TFF_AVAILABLE:\n",
    "    print(\"⚠️  SKIPPING FEDERATED TRAINING - TensorFlow Federated not available\")\n",
    "    print(\"   To run federated experiments, use Python 3.9-3.11 with:\")\n",
    "    print(\"   pip install tensorflow-federated\")\n",
    "    federated_trainer = None\n",
    "    federated_metrics = None\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING FEDERATED TRAINING\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # Create federated trainer\n",
    "    federated_trainer = FederatedTrainer(\n",
    "        client_datasets=client_datasets,\n",
    "        test_data=(X_test, y_test)\n",
    "    )\n",
    "\n",
    "    # Train federated model\n",
    "    federated_metrics = federated_trainer.train(\n",
    "        num_rounds=ExperimentConfig.NUM_ROUNDS,\n",
    "        client_fraction=ExperimentConfig.CLIENT_FRACTION,\n",
    "        local_epochs=ExperimentConfig.LOCAL_EPOCHS\n",
    "    )\n",
    "\n",
    "    print(\"\\nFederated training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15445d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get federated final metrics\n",
    "if TFF_AVAILABLE and federated_trainer:\n",
    "    federated_final_metrics = federated_trainer.get_final_test_metrics()\n",
    "\n",
    "    print(\"\\nFederated Model - Final Test Set Results:\")\n",
    "    print(\"=\"*50)\n",
    "    for metric, value in federated_final_metrics.items():\n",
    "        print(f\"{metric:.<35} {value if isinstance(value, int) else f'{value:.4f}'}\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"⚠️  Skipped - TensorFlow Federated not available\")\n",
    "    federated_final_metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9209b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save federated results\n",
    "if TFF_AVAILABLE and federated_trainer:\n",
    "    federated_results_path = federated_trainer.save_results()\n",
    "    print(f\"\\nFederated results saved to: {federated_results_path}\")\n",
    "else:\n",
    "    print(\"⚠️  Skipped - TensorFlow Federated not available\")\n",
    "    federated_results_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51a70c",
   "metadata": {},
   "source": [
    "## 6. Results Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90148fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate performance summary table\n",
    "if TFF_AVAILABLE and federated_final_metrics:\n",
    "    summary_table = create_performance_summary_table(\n",
    "        centralized_test_metrics,\n",
    "        federated_final_metrics\n",
    "    )\n",
    "    print(summary_table)\n",
    "else:\n",
    "    print(\"⚠️  Skipped - TensorFlow Federated not available\")\n",
    "    print(\"\\nCentralized Model Performance:\")\n",
    "    print(\"=\"*50)\n",
    "    for metric, value in centralized_test_metrics.items():\n",
    "        print(f\"{metric:.<35} {value:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training convergence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if TFF_AVAILABLE and federated_metrics:\n",
    "    centralized_training_metrics = centralized_trainer.get_training_metrics()\n",
    "\n",
    "    fig = plot_training_convergence(\n",
    "        centralized_training_metrics,\n",
    "        federated_metrics\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Skipping convergence comparison - TensorFlow Federated not available\")\n",
    "    print(\"   Can only show centralized training metrics\")\n",
    "    \n",
    "    # Plot centralized training only\n",
    "    history = centralized_trainer.get_training_metrics()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    ax1.plot(history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_title('Centralized Training - Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history['loss'], label='Train Loss', linewidth=2)\n",
    "    ax2.plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title('Centralized Training - Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fda78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final performance comparison\n",
    "if TFF_AVAILABLE and federated_final_metrics:\n",
    "    fig = plot_final_comparison(\n",
    "        centralized_test_metrics,\n",
    "        federated_final_metrics\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Skipped - TensorFlow Federated not available\")\n",
    "    print(\"   Cannot compare without federated results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot client participation heatmap\n",
    "if TFF_AVAILABLE and federated_metrics:\n",
    "    fig = plot_client_participation(federated_metrics)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Skipped - TensorFlow Federated not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36237e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save all visualizations\n",
    "if TFF_AVAILABLE and federated_results_path:\n",
    "    print(\"Generating all visualizations...\")\n",
    "\n",
    "    figures = generate_all_visualizations(\n",
    "        centralized_results_path,\n",
    "        federated_results_path\n",
    "    )\n",
    "\n",
    "    print(\"\\nGenerated figures:\")\n",
    "    for name, path in figures.items():\n",
    "        print(f\"  - {name}: {path}\")\n",
    "else:\n",
    "    print(\"⚠️  Skipped - TensorFlow Federated not available\")\n",
    "    print(\"   Cannot generate comparison visualizations without federated results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8c166",
   "metadata": {},
   "source": [
    "## 7. Experiment Analysis and Insights\n",
    "\n",
    "### Key Questions to Address:\n",
    "\n",
    "1. **Convergence Behavior**\n",
    "   - How does federated learning convergence compare to centralized?\n",
    "   - Are there oscillations or instability in federated training?\n",
    "   - How many rounds are needed to reach comparable performance?\n",
    "\n",
    "2. **Generalization Performance**\n",
    "   - What is the accuracy gap between centralized and federated?\n",
    "   - Is the gap acceptable for privacy-preserving scenarios?\n",
    "   - How does test loss compare?\n",
    "\n",
    "3. **Client Heterogeneity Impact**\n",
    "   - How does non-IID data distribution affect learning?\n",
    "   - Are certain clients more influential?\n",
    "   - Does client sampling strategy matter?\n",
    "\n",
    "4. **Practical Implications**\n",
    "   - When is federated learning a viable alternative?\n",
    "   - What are the trade-offs in communication vs performance?\n",
    "   - How can we improve federated learning performance?\n",
    "\n",
    "### Next Steps for Research:\n",
    "\n",
    "- Experiment with different client fractions\n",
    "- Vary the degree of non-IID data\n",
    "- Test different aggregation strategies\n",
    "- Analyze communication efficiency\n",
    "- Implement differential privacy mechanisms\n",
    "- Compare with other federated algorithms (FedProx, FedAdam, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0768627",
   "metadata": {},
   "source": [
    "## 8. Experiment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e598ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final experiment summary\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nExperiment Configuration:\")\n",
    "print(f\"  - Dataset size: {len(X)}\")\n",
    "print(f\"  - Number of clients: {ExperimentConfig.NUM_CLIENTS}\")\n",
    "print(f\"  - Federated rounds: {ExperimentConfig.NUM_ROUNDS}\")\n",
    "print(f\"  - Centralized epochs: {ExperimentConfig.CENTRALIZED_EPOCHS}\")\n",
    "print(f\"  - Client fraction: {ExperimentConfig.CLIENT_FRACTION}\")\n",
    "print(f\"  - Local epochs: {ExperimentConfig.LOCAL_EPOCHS}\")\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"  Centralized Test Accuracy: {centralized_test_metrics['test_accuracy']:.4f}\")\n",
    "\n",
    "if TFF_AVAILABLE and federated_final_metrics:\n",
    "    print(f\"  Federated Test Accuracy:   {federated_final_metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"  Performance Gap:           {abs(centralized_test_metrics['test_accuracy'] - federated_final_metrics['test_accuracy']):.4f}\")\n",
    "else:\n",
    "    print(f\"  Federated Test Accuracy:   N/A (TensorFlow Federated not available)\")\n",
    "    print(f\"  Performance Gap:           N/A\")\n",
    "\n",
    "print(\"\\nArtifacts Generated:\")\n",
    "print(f\"  - Centralized results: {centralized_results_path}\")\n",
    "print(f\"  - Centralized model: {centralized_model_path}\")\n",
    "\n",
    "if TFF_AVAILABLE and federated_results_path:\n",
    "    print(f\"  - Federated results: {federated_results_path}\")\n",
    "    print(f\"  - Visualizations: {ExperimentConfig.FIGURES_DIR}\")\n",
    "else:\n",
    "    print(f\"  - Federated results: N/A\")\n",
    "    print(f\"  - Visualizations: Limited (centralized only)\")\n",
    "\n",
    "if not TFF_AVAILABLE:\n",
    "    print(\"\\n\" + \"⚠️ \"*35)\n",
    "    print(\"NOTE: Federated learning experiments were skipped\")\n",
    "    print(\"      TensorFlow Federated is not available in this environment\")\n",
    "    print(\"      To run full experiments, use Python 3.9-3.11 with:\")\n",
    "    print(\"      pip install tensorflow-federated\")\n",
    "    print(\"⚠️ \"*35)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Centralized training results saved and ready for analysis\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
